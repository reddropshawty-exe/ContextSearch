# Требования к подсистеме тестирования качества поиска (Retrieval Evaluation)

## 1. Назначение

Подсистема предназначена для:

- оценки качества работы поиска по размеченному набору данных;
- сравнения конфигураций поиска (модель, хранилище, BM25, реврайтер, режим ранжирования);
- воспроизводимого хранения результатов прогона и метрик.

Целевая формула:

`(EmbeddingSpec + Store + BM25 + Query(author)) -> SearchResults -> Metrics`

## 2. Основные сущности

### 2.1 TestSuite / Dataset
- Набор документов.
- Набор тест-кейсов.

### 2.2 TestCase
- `query_text`: исходный запрос.
- `relevance_labels`:
  - MVP: список релевантных `document_id`.
  - расширение: graded relevance (0..3), `chunk_id`.
- `source`: `user` или `rewriter:<id>`.
- `metadata`: тема, категория, сложность и т.д.

### 2.3 ExperimentConfig
- `embedding_spec_id`
- `store_type`
- `use_bm25`
- `ranking_mode` (`vector`, `bm25`, `hybrid_rrf`)
- `query_rewriter`
- `top_k`, `rrf_k`, веса
- версии зависимостей (опционально)

### 2.4 ExperimentRun
- Ссылка на `ExperimentConfig`.
- Ссылка на тестовый набор.
- По каждому тест-кейсу:
  - ранжированный список результатов;
  - метрики.

## 3. Метрики (обязательные)

- Precision@k
- Recall@k
- MRR@k
- nDCG@k (если graded relevance)
- Hit@k

Желательно:
- метрики отдельно для document-level и chunk-level.

## 4. Требования к разметке

### MVP
- добавить документ в тестовый набор;
- создать кейс: запрос -> список релевантных doc_id;
- редактирование/сохранение.

### Расширение
- graded relevance;
- релевантные chunk_id;
- many-to-many связь запросов и документов.

## 5. UI-режим “Тестирование / Разметка”

- Создать/удалить набор.
- Выбрать документы из индекса.
- Привязать запросы к документам.
- Для запроса хранить автора (`user` / `rewriter:<name>:<version>`).
- Показывать оригинал, rewrite-варианты, и выбранные варианты для прогона.
- Запуск прогона из UI с параметрами конфигурации.
- Отображение сводной таблицы метрик.

## 6. Хранение результатов

- SQLite (отдельные таблицы подсистемы evaluation).
- Повторный просмотр прогонов.
- Привязка к конфигурации, версии реврайтера, спекам.
- Сравнение прогонов (diff по метрикам).

## 7. Нефункциональные требования

1. Воспроизводимость.
2. Расширяемость (метрики/реврайтеры).
3. Изоляция от рабочей базы (dataset_id/таблицы/отдельный root).
4. Прозрачность (score breakdown: vector/bm25/rrf).

## 8. Статус реализации

В проект добавлен базовый каркас:

- модели подсистемы evaluation;
- библиотека метрик;
- раннер прогона;
- SQLite-репозиторий для сохранения наборов, кейсов, прогонов, результатов и метрик.

Интеграция с UI (режим разметки) и полноценный diff-просмотр прогонов — следующий этап.
